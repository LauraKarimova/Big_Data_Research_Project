{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "EalvwCm2zq7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inTGWmxbbnI3",
        "outputId": "d8a56711-eb52-479a-8bb2-81b74735830e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/instadeepai/jumanji.git\n",
            "  Cloning https://github.com/instadeepai/jumanji.git to /tmp/pip-req-build-lj4bw0be\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/instadeepai/jumanji.git /tmp/pip-req-build-lj4bw0be\n",
            "  Resolved https://github.com/instadeepai/jumanji.git to commit 10958866909d434ba50edc1915247e4cebc3cb3e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (1.21.6)\n",
            "Requirement already satisfied: jax>=0.2.26 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.3.25)\n",
            "Collecting chex>=0.1.3\n",
            "  Downloading chex-0.1.6-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-env>=1.5\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Collecting matplotlib>=3.3.4\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (4.4.0)\n",
            "Collecting Pillow>=9.0.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygame>=2.0.0\n",
            "  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gym>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.25.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.74 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.3.25+cuda11.cudnn805)\n",
            "Collecting brax>=0.0.10\n",
            "  Downloading brax-0.1.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.3/471.3 KB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax\n",
            "  Downloading flax-0.6.5-py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (2.11.3)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mujoco\n",
            "  Downloading mujoco-2.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.51.1)\n",
            "Collecting trimesh==3.9.35\n",
            "  Downloading trimesh-3.9.35-py3-none-any.whl (639 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m639.3/639.3 KB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxopt\n",
            "  Downloading jaxopt-0.6-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytinyrenderer\n",
            "  Downloading pytinyrenderer-0.0.13-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from trimesh==3.9.35->brax>=0.0.10->jumanji==0.1.4) (57.4.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.3->jumanji==0.1.4) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.3->jumanji==0.1.4) (0.12.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (6.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (2.2.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.2.26->jumanji==0.1.4) (3.3.0)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (2.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym>=0.22.0->jumanji==0.1.4) (3.12.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->jumanji==0.1.4) (1.15.0)\n",
            "Collecting tensorstore\n",
            "  Downloading tensorstore-0.1.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich>=11.1\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orbax\n",
            "  Downloading orbax-0.1.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jax>=0.2.26\n",
            "  Downloading jax-0.4.3.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.4) (1.0.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.4) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->brax>=0.0.10->jumanji==0.1.4) (2.0.1)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.8/dist-packages (from mujoco->brax>=0.0.10->jumanji==0.1.4) (3.1.6)\n",
            "Collecting glfw\n",
            "  Downloading glfw-2.5.6-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 KB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->brax>=0.0.10->jumanji==0.1.4) (3.19.6)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: etils in /usr/local/lib/python3.8/dist-packages (from orbax->flax->brax>=0.0.10->jumanji==0.1.4) (1.0.0)\n",
            "Collecting cached_property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.8/dist-packages (from orbax->flax->brax>=0.0.10->jumanji==0.1.4) (5.10.2)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: jumanji, jax\n",
            "  Building wheel for jumanji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jumanji: filename=jumanji-0.1.4-py3-none-any.whl size=160843 sha256=30f5a9a05c3d2b7b656a55e9adf3ad323157266266e7e0956f2de8f9bf934925\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rzg4pmgy/wheels/df/c6/15/caef8b041b929f4f3b7a55a217c00f24c6931fe57ae40d9bd9\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.3-py3-none-any.whl size=1384905 sha256=18fbc47d5c12aeb524532ab70cf67cea237e600a1dca3bcd7e9ca74671aba2f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/38/24/69c60b74118b6de655c576685cbe9c654f868ac27597ee5c98\n",
            "Successfully built jumanji jax\n",
            "Installing collected packages: pytinyrenderer, glfw, dataclasses, cached_property, trimesh, tensorstore, tensorboardX, pygments, pygame, Pillow, mujoco, mdurl, fonttools, dm-env, contourpy, matplotlib, markdown-it-py, jax, rich, jaxopt, chex, optax, orbax, flax, brax, jumanji\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.25\n",
            "    Uninstalling jax-0.3.25:\n",
            "      Successfully uninstalled jax-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.4.0 brax-0.1.1 cached_property-1.5.2 chex-0.1.6 contourpy-1.0.7 dataclasses-0.6 dm-env-1.6 flax-0.6.5 fonttools-4.38.0 glfw-2.5.6 jax-0.4.3 jaxopt-0.6 jumanji-0.1.4 markdown-it-py-2.1.0 matplotlib-3.6.3 mdurl-0.1.2 mujoco-2.3.2 optax-0.1.4 orbax-0.1.1 pygame-2.1.2 pygments-2.14.0 pytinyrenderer-0.0.13 rich-13.3.1 tensorboardX-2.6 tensorstore-0.1.31 trimesh-3.9.35\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/instadeepai/jumanji.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U jax jaxlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R59Arb1qxjUW",
        "outputId": "ba71912d-8aa0-4ee9-b1c0-4483935e48c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (0.4.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.8/dist-packages (0.3.25+cuda11.cudnn805)\n",
            "Collecting jaxlib\n",
            "  Downloading jaxlib-0.4.3-cp38-cp38-manylinux2014_x86_64.whl (72.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax) (1.7.3)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.25+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.25+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.25+cuda11.cudnn805\n",
            "Successfully installed jaxlib-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib==3.3.4"
      ],
      "metadata": {
        "id": "3c4yDpmqfRHi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "b422160d-911c-4fad-8056-a71f347e2a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.3.4\n",
            "  Downloading matplotlib-3.3.4-cp38-cp38-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.4) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.6.3\n",
            "    Uninstalling matplotlib-3.6.3:\n",
            "      Successfully uninstalled matplotlib-3.6.3\n",
            "Successfully installed matplotlib-3.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nEpg3aGpY0CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzqMPoLYbxBy",
        "outputId": "9edb8b72-dfeb-4de0-8030-7308a22e2298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import numpy as np\n",
        "from jumanji.wrappers import AutoResetWrapper\n",
        "\n",
        "from gym import spaces\n",
        "from collections import deque\n",
        "# check and use GPU if available if not use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from torch.distributions import MultivariateNormal,Categorical"
      ],
      "metadata": {
        "id": "INab76B918h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic function initialization\n"
      ],
      "metadata": {
        "id": "1e39WsESz0t5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Python function named \"flatten\" that takes in one argument \"obs\". It creates an empty list \"p\", then appends various attributes from the \"obs\" object to this list using NumPy's \"np.append\" function."
      ],
      "metadata": {
        "id": "a5YSRNW700Mh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT9XH1bkbwhS"
      },
      "outputs": [],
      "source": [
        "def flatten(obs):\n",
        "  p=[]\n",
        "  p = np.append(obs.ems.x1,obs.ems.x2)\n",
        "  p = np.append(p,obs.ems.y1)\n",
        "  p = np.append(p,obs.ems.y2)\n",
        "  p = np.append(p,obs.ems.z1)\n",
        "  p = np.append(p,obs.ems.z2)\n",
        "  p = np.append(p,obs.ems_mask.flatten())\n",
        "  p = np.append(p,obs.items.x_len)\n",
        "  p = np.append(p,obs.items.y_len)\n",
        "  p = np.append(p,obs.items.z_len)\n",
        "  p = np.append(p,obs.items_mask.flatten())\n",
        "  p = np.append(p,obs.items_placed.flatten())\n",
        "  return p "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"ReplayBuffer\" class stores and retrieves tuples of (state, next_state, action, reward, done) that are used to train the reinforcement learning model. The class has methods for adding new tuples to the buffer and for randomly sampling a batch of tuples from the buffer for training. The buffer has a maximum size, and if the buffer is full, the oldest tuple is replaced by the newest tuple."
      ],
      "metadata": {
        "id": "1tXA5mgu1lFb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xiO8uZ4bxEZ"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=1e6):\n",
        "        self.storage = []\n",
        "        self.max_size = max_size\n",
        "        self.ptr = 0\n",
        "\n",
        "    def add(self, data):\n",
        "        if len(self.storage) == self.max_size:\n",
        "            self.storage[int(self.ptr)] = data\n",
        "            self.ptr = (self.ptr + 1) % self.max_size\n",
        "        else:\n",
        "            self.storage.append(data)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
        "        x, y, u, r, d = [], [], [], [], []\n",
        "\n",
        "        for i in ind: \n",
        "            X, Y, U, R, D = self.storage[i]\n",
        "            x.append(np.array(X, copy=False))\n",
        "            y.append(np.array(Y, copy=False))\n",
        "            u.append(np.array(U, copy=False))\n",
        "            r.append(np.array(R, copy=False))\n",
        "            d.append(np.array(D, copy=False))\n",
        "\n",
        "        return np.array(x), np.array(y), np.array(u).reshape(-1,1), np.array(r).reshape(-1,1) , np.array(d).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a PyTorch implementation of a feedforward neural network model, represented as a class called \"FeedForwardNeuralNet\". The class constructor takes three arguments: \"state_size\", \"action_size\", and \"hidden_size\", which specify the sizes of the input, output, and hidden layers, respectively. The neural network model consists of three fully connected (linear) layers and an output layer, all implemented as PyTorch nn.Linear objects. The forward() method specifies the forward pass of the model, applying ReLU activation functions after each hidden layer and returning the output layer. The overall purpose of this code is to provide a template for building and training feedforward neural networks for use in reinforcement learning applications."
      ],
      "metadata": {
        "id": "zHlb46jb123Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi022XHxb19K"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNeuralNet(nn.Module):\n",
        "    def __init__(self, state_size, action_size, hidden_size):\n",
        "        super(FeedForwardNeuralNet, self).__init__()\n",
        "        self.dense_layer_1 = nn.Linear(state_size, hidden_size)\n",
        "        self.dense_layer_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dense_layer_3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, action_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.dense_layer_1(x))\n",
        "        x = F.relu(self.dense_layer_2(x))\n",
        "        x = F.relu(self.dense_layer_3(x))\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a DQN class that includes a feedforward neural network with two identical instances - a train network and a target network. It also includes methods for selecting actions using an epsilon-greedy policy, training the train network using a replay buffer and a loss function, and updating the target network periodically. The code also uses PyTorch for neural network training and optimization."
      ],
      "metadata": {
        "id": "nt0r7Y6L2Iuv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfV3hRZHbxJZ"
      },
      "outputs": [],
      "source": [
        "class DQN():\n",
        "  def __init__(self, state_size, action_size, hidden_size, learning_rate ):\n",
        "    self.action_size = action_size\n",
        "    self.train_net = FeedForwardNeuralNet(state_size, action_size, hidden_size).to(device)\n",
        "    self.target_net = FeedForwardNeuralNet(state_size, action_size, hidden_size).to(device)\n",
        "    self.target_net.load_state_dict(self.train_net.state_dict())\n",
        "    self.optimizer = optim.Adam(self.train_net.parameters(), lr=learning_rate)\n",
        "\n",
        "        \n",
        "  def select_action(self, state, epsilon):\n",
        "    # select action according to epsilon-greedy method\n",
        "    num_ems, num_items = env.action_spec().num_values \n",
        "    if np.random.rand() <= epsilon:\n",
        "      ems_item_id = jax.random.choice( \n",
        "          key=jax.random.PRNGKey(0), \n",
        "          a=num_ems * num_items, \n",
        "          p=timestep.observation.action_mask.flatten(), \n",
        "          ) \n",
        "      ems_id, item_id = jnp.divmod(ems_item_id, num_items) \n",
        "      # Wrap the action as a jax array of shape (2,) \n",
        "      action = jnp.array([ems_id, item_id]) \n",
        "    else:\n",
        "      # greedy action is the largest Q value from the train network based on the input\n",
        "      with torch.no_grad():\n",
        "        input_state = torch.FloatTensor(state).to(device)\n",
        "        # feed input into the network and get the max action value\n",
        "        ems_item_id = self.train_net(input_state).max(0)[1].view(-1)\n",
        "        ems_item_id = int(ems_item_id)\n",
        "        ems_id, item_id = jnp.divmod(ems_item_id, num_items) \n",
        "        action = jnp.array([ems_id, item_id]) \n",
        "        \n",
        "    return action\n",
        "\n",
        "  def train(self, replay_buffer, batch_size, discount):\n",
        "    # train the training network\n",
        "    # sample a batch from the replay buffer\n",
        "    x0, x1, a, r, d = replay_buffer.sample(batch_size)\n",
        "    #x0, x1, a, r = replay_buffer.sample(batch_size)\n",
        "\n",
        "    # turn batches into tensors and attack to GPU if available\n",
        "    state_batch = torch.FloatTensor(x0).to(device)\n",
        "    next_state_batch = torch.FloatTensor(x1).to(device)\n",
        "    action_batch = torch.LongTensor(a).to(device)\n",
        "    reward_batch = torch.FloatTensor(r).to(device)\n",
        "    done_batch = torch.FloatTensor(1 - d).to(device)\n",
        "\n",
        "    # get train net Q values\n",
        "    train_q = self.train_net(state_batch)\n",
        "        \n",
        "    # get target net Qvalues\n",
        "    with torch.no_grad():\n",
        "      target_net_q = reward_batch + done_batch * discount * \\\n",
        "                     torch.max( self.target_net(next_state_batch).detach(), dim=1)[0].view(batch_size, -1)\n",
        "\n",
        "    # create loss function\n",
        "    loss_fn = nn.MSELoss()\n",
        "    # get loss between train q values and target q values\n",
        "    loss = loss_fn(train_q, target_net_q)\n",
        "    # optimize the parameters with the loss\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    # we return the loss so we can monitor loss and debug the network if necessary\n",
        "    return loss.detach().cpu().numpy()\n",
        "    \n",
        "  def update_target_network(self, num_iter, update_every):\n",
        "    # update target network every so often\n",
        "    # hard target network update: updates target network fully with train network params\n",
        "    if num_iter % update_every == 0:\n",
        "      self.target_net.load_state_dict(self.train_net.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code initializes the environment and sets up hyperparameters for a Deep Q-Network (DQN) agent to solve the Bin Packing problem. The environment is created using the Jumanji library, and the agent is initialized with a DQN network with specified sizes for the input and hidden layers, a learning rate, and an action size. Additionally, the hyperparameters for training the DQN are set, including the number of episodes to run the agent for, when to start training, the size of the replay buffer, and the epsilon-greedy exploration values."
      ],
      "metadata": {
        "id": "VqAbgRAP2WyV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW5HWv3eraKf"
      },
      "outputs": [],
      "source": [
        "# initialize environment\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jumanji\n",
        "env = jumanji.make(\"BinPack-toy-v0\")\n",
        "env = AutoResetWrapper(env) \n",
        "dummy_obs = env.observation_spec().generate_value()\n",
        "dummy_obs = flatten(env.observation_spec().generate_value())\n",
        "num_ems, num_items = env.action_spec().num_values\n",
        "\n",
        "action_size =  num_ems * num_items\n",
        "state_size = dummy_obs.shape[0]\n",
        "\n",
        "# set seed\n",
        "seed = 31\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# hyperparameters\n",
        "episodes = 100000 # run agent for this many episodes\n",
        "start_training_after = 10000 # collect data for this many timesteps before training\n",
        "hidden_size = 128 # number of units in NN hidden layers\n",
        "learning_rate = 0.005 # learning rate for optimizer\n",
        "update_target_every_ts = 1000 # update target network after this many steps\n",
        "batch_size = 128 # mini batch size we train network on\n",
        "discount = 0.8 # gamma value\n",
        "\n",
        "epsilon_start = 1.0 # epsilon start value\n",
        "epsilon_min = 0.01  # epsilon end value\n",
        "epsilon_decay_steps = episodes * .95 # decay epsilon over this many episodes\n",
        "epsilon_step = (epsilon_start - epsilon_min)/(epsilon_decay_steps) # decrement epsilon by this amount every timestep\n",
        "\n",
        "# create replay buffer\n",
        "replay_size = 25000\n",
        "replay_buffer = ReplayBuffer(max_size=replay_size)\n",
        "\n",
        "# create cartpole agent\n",
        "BinPacking = DQN(state_size, action_size, hidden_size, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = FeedForwardNeuralNet(state_size, action_size, hidden_size)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7qyhMCgwL_v",
        "outputId": "551b2b63-30bd-4029-c21f-54790f71fb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeedForwardNeuralNet(\n",
            "  (dense_layer_1): Linear(in_features=380, out_features=128, bias=True)\n",
            "  (dense_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (dense_layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (output): Linear(in_features=128, out_features=800, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements the training loop for a reinforcement learning agent that solves the bin packing problem. In each episode, the agent selects an action based on its current policy, interacts with the environment, receives a reward, and updates its policy based on the observed experience. The training loop runs for a specified number of episodes and stops early if the average reward across the previous episodes exceeds a certain threshold. The training uses a replay buffer, batch training, and target network to improve the learning efficiency. During the training, various statistics such as the total reward, episode length, and loss are printed every certain number of episodes. The epsilon value is also updated in each episode to balance the exploration and exploitation tradeoff."
      ],
      "metadata": {
        "id": "nE6Qjm4f2uHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "IRblutavhrUM",
        "outputId": "631ca07e-079a-4916-8b30-25432d4904b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 850 Timestep: 10037 Total reward: 0.5 Episode length: 12.0 Epsilon: 0.99 Loss: 0.056\n",
            "Episode: 860 Timestep: 10148 Total reward: 0.5 Episode length: 11.1 Epsilon: 0.99 Loss: 0.030\n",
            "Episode: 870 Timestep: 10267 Total reward: 0.5 Episode length: 11.9 Epsilon: 0.99 Loss: 0.051\n",
            "Episode: 880 Timestep: 10383 Total reward: 0.5 Episode length: 11.6 Epsilon: 0.99 Loss: 0.062\n",
            "Episode: 890 Timestep: 10504 Total reward: 0.5 Episode length: 12.1 Epsilon: 0.99 Loss: 0.021\n",
            "Episode: 900 Timestep: 10619 Total reward: 0.5 Episode length: 11.5 Epsilon: 0.99 Loss: 0.030\n",
            "Episode: 910 Timestep: 10734 Total reward: 0.5 Episode length: 11.5 Epsilon: 0.99 Loss: 0.012\n",
            "Episode: 920 Timestep: 10854 Total reward: 0.5 Episode length: 12.0 Epsilon: 0.99 Loss: 0.043\n",
            "Episode: 930 Timestep: 10970 Total reward: 0.5 Episode length: 11.6 Epsilon: 0.99 Loss: 0.011\n",
            "Episode: 940 Timestep: 11091 Total reward: 0.5 Episode length: 12.1 Epsilon: 0.99 Loss: 0.041\n",
            "Episode: 950 Timestep: 11201 Total reward: 0.5 Episode length: 11.0 Epsilon: 0.99 Loss: 0.030\n",
            "Episode: 960 Timestep: 11315 Total reward: 0.5 Episode length: 11.4 Epsilon: 0.99 Loss: 0.048\n",
            "Episode: 970 Timestep: 11423 Total reward: 0.5 Episode length: 10.8 Epsilon: 0.99 Loss: 0.029\n",
            "Episode: 980 Timestep: 11543 Total reward: 0.5 Episode length: 12.0 Epsilon: 0.99 Loss: 0.039\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-af3c0c260b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_training_after\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;31m# train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0mstats_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mBinPacking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m       \u001b[0;31m# update the target network every (if conditions are met in update_target_network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0mBinPacking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_target_every_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-be1173ce277c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, replay_buffer, batch_size, discount)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# we return the loss so we can monitor loss and debug the network if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# update step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mstep_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import warnings  \n",
        "warnings.filterwarnings('ignore') \n",
        "stats_rewards_list = [] # store stats for plotting in this \n",
        "batch_states = [] \n",
        "answ= []\n",
        "stats_every = 10 # print stats every this many episodes \n",
        "total_reward = 0 \n",
        "timesteps = 0 \n",
        "episode_length = 0 \n",
        "epsilon = epsilon_start \n",
        " \n",
        " \n",
        "step_fn = jax.jit(env.step) \n",
        "reset_fn = jax.jit(env.reset) \n",
        " \n",
        "for ep in range(episodes): \n",
        "  key = jax.random.PRNGKey(seed) \n",
        "  state, timestep = reset_fn(key) \n",
        "  state_flt = flatten(timestep.observation) \n",
        " \n",
        "  stats_loss = 0 \n",
        "     \n",
        "  # stopping condition for training if agent reaches the amount of reward \n",
        "  if len(stats_rewards_list) > stats_every and np.mean(stats_rewards_list[-stats_every:],axis=0)[1] > 190: \n",
        "      print(\"Stopping at episode {} with average rewards of {} in last {} episodes\". \n",
        "          format(ep, np.mean(stats_rewards_list[-stats_every:],axis=0)[1], stats_every)) \n",
        "      break   \n",
        "     \n",
        "  # train in each episode until episode is done \n",
        "  while True: \n",
        "    timesteps += 1 \n",
        "    # select an action from the agent's policy \n",
        "    action = BinPacking.select_action(state_flt, epsilon)\n",
        "    # enter action into the env \n",
        "    #next_state, timestep = jax.jit(env.step)(state, action)  \n",
        "    next_state, timestep = step_fn(state, action) \n",
        "    next_state_flt = flatten(timestep.observation) \n",
        "    reward =np.array(timestep.reward.flatten())[0]\n",
        "    total_reward += reward \n",
        "    episode_length += 1 \n",
        " \n",
        " \n",
        "    #print(\"timestep.extras['volume_utilization'].flatten()\") \n",
        "    #print(timestep.extras['volume_utilization'].flatten()[0]) \n",
        " \n",
        "    batch_states.append(state) \n",
        "    #done = True if timestep.last() else False \n",
        "    done = True if reward!=0 else False\n",
        "    if done: \n",
        "      reward = -1\n",
        "      #replay_buffer.add((state_flt, np.zeros(state_flt.shape), action, reward, done))\n",
        "      replay_buffer.add((state_flt, next_state_flt, action, reward, done))\n",
        "      #answ.append((state_flt, next_state_flt, action, reward, done)) \n",
        "      stats_rewards_list.append((ep, total_reward, episode_length)) \n",
        "      total_reward = 0 \n",
        "      episode_length = 0 \n",
        "      epsilon -= epsilon_step \n",
        "      if epsilon < epsilon_min: \n",
        "        epsilon = epsilon_min \n",
        "                 \n",
        "      if timesteps > start_training_after and ep % stats_every == 0: \n",
        "        print('Episode: {}'.format(ep), \n",
        "                  'Timestep: {}'.format(timesteps), \n",
        "                  'Total reward: {:.1f}'.format(np.mean(stats_rewards_list[-stats_every:],axis=0)[1]), \n",
        "                  'Episode length: {:.1f}'.format(np.mean(stats_rewards_list[-stats_every:],axis=0)[2]), \n",
        "                  'Epsilon: {:.2f}'.format(epsilon), \n",
        "                  'Loss: {:.3f}'.format(stats_loss)) \n",
        "      # for i in answ:\n",
        "      #   replay_buffer.add((i[0], i[1], i[2], reward, i[4])) \n",
        "      # answ = []  \n",
        "      break \n",
        "    else:\n",
        "      #answ.append((state_flt, next_state_flt, action, reward, done)) \n",
        "      replay_buffer.add((state_flt, next_state_flt, action, reward, done)) \n",
        "    state = next_state \n",
        "    state_flt= next_state_flt\n",
        "    if timesteps > start_training_after: \n",
        "      # train the agent \n",
        "      stats_loss += BinPacking.train(replay_buffer, batch_size, discount) \n",
        "      # update the target network every (if conditions are met in update_target_network) \n",
        "      BinPacking.update_target_network(timesteps, update_target_every_ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments and Evaluation"
      ],
      "metadata": {
        "id": "7IuL45wO26ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The get_running_stat function is used to plot the training progress of the reinforcement learning agent. It takes the stats_rewards_list, which contains the total reward and episode length for each episode during training, and calculates the running average of the total reward and episode length over a window of 10 episodes. It then plots the running average and the raw data for the total reward as a function of episode number. The x-axis is the episode number, and the y-axis is the total reward. "
      ],
      "metadata": {
        "id": "zGagJ0Xi27Hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yLTbh-DON0fQ",
        "outputId": "0469afb7-faf2-49a4-e29d-20f1e9028561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Episode Reward')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot stats\n",
        "def get_running_stat(stat, stat_len):\n",
        "    cum_sum = np.cumsum(np.insert(stat, 0, 0)) \n",
        "    return (cum_sum[stat_len:] - cum_sum[:-stat_len]) / stat_len\n",
        "\n",
        "episode, r, l = np.array(stats_rewards_list).T\n",
        "cum_r = get_running_stat(r, 10)\n",
        "cum_l = get_running_stat(l, 10)\n",
        "\n",
        "# plot rewards\n",
        "plt.plot(episode[-len(cum_r):], cum_r)\n",
        "plt.plot(episode, r, alpha=0.5)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Episode Reward')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-DafSX3NN2yY",
        "outputId": "2af05090-93e4-48ae-ab20-75745bdac1f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Episode Length')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot episode lengths\n",
        "plt.plot(episode[-len(cum_l):], cum_l)\n",
        "plt.plot(episode, l, alpha=0.5)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Episode Length')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code appears to be using a loop to iterate over a range of numbers from 0 to 999 and then calls a function env.render() on each iteration with an argument of batch_states[i]. The time.sleep(1) call will pause the program for one second on each iteration, causing a one second delay between each call to env.render().\n",
        "\n",
        "A render() method displays the state of the environment, this code used to animate a sequence of states represented by batch_states."
      ],
      "metadata": {
        "id": "r9zuMPcevJrw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "BLpWR1TQbxQy",
        "outputId": "4c856e05-8efc-49e6-a374-0234c7d21179"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-26a1605840cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jumanji/wrappers.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdynamics\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jumanji/environments/combinatorial/binpack/env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mdynamics\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \"\"\"\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env_viewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jumanji/environments/combinatorial/binpack/env_viewer.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_collection3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_overlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     def animation(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jumanji/environments/combinatorial/binpack/env_viewer.py\u001b[0m in \u001b[0;36m_display\u001b[0;34m(self, fig)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjumanji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# Required to update render when not using Jupyter Notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \"\"\"\n\u001b[1;32m    352\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m                 result = print_method(\n\u001b[0m\u001b[1;32m   2211\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \"\"\"\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    511\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    406\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mpl_toolkits/mplot3d/axes3d.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Then axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                 \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;31m# Then rest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mpl_toolkits/mplot3d/axis3d.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0medgep1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtickdir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 - info['tick']['inward_factor'] * ticksign * tickdelta)\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Get position of label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mpl_toolkits/mplot3d/proj3d.py\u001b[0m in \u001b[0;36mproj_transform\u001b[0;34m(xs, ys, zs, M)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m    143\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vec_pad_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_proj_transform_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mpl_toolkits/mplot3d/proj3d.py\u001b[0m in \u001b[0;36m_proj_transform_vec\u001b[0;34m(vec, M)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_proj_transform_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mvecw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvecw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# clip here..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "for i in range(1000):\n",
        "  env.render(batch_states[i])\n",
        "  time.sleep(1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EalvwCm2zq7V",
        "1e39WsESz0t5",
        "7IuL45wO26ux"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}